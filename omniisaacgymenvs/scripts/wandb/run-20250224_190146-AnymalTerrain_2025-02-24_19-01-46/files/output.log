Actor MLP: Actor(
  (priv_encoder): Sequential(
    (0): Linear(in_features=0, out_features=64, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=64, out_features=20, bias=True)
    (3): ELU(alpha=1.0)
  )
  (history_encoder): StateHistoryEncoder(
    (activation_fn): ELU(alpha=1.0)
    (encoder): Sequential(
      (0): Linear(in_features=48, out_features=30, bias=True)
      (1): ELU(alpha=1.0)
    )
    (conv_layers): Sequential(
      (0): Conv1d(30, 20, kernel_size=(4,), stride=(2,))
      (1): ELU(alpha=1.0)
      (2): Conv1d(20, 10, kernel_size=(2,), stride=(1,))
      (3): ELU(alpha=1.0)
      (4): Flatten(start_dim=1, end_dim=-1)
    )
    (linear_output): Sequential(
      (0): Linear(in_features=30, out_features=20, bias=True)
      (1): ELU(alpha=1.0)
    )
  )
  (actor_backbone): Sequential(
    (0): Linear(in_features=68, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
  )
  (actor_leg_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=12, bias=True)
    (5): Tanh()
  )
)
Critic MLP: Critic(
  (critic_backbone): Sequential(
    (0): Linear(in_features=48, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
  )
  (critic_leg_control_head): Sequential(
    (0): Linear(in_features=128, out_features=128, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=128, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): Linear(in_features=128, out_features=1, bias=True)
  )
)
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ActorCritic                              12
├─Actor: 1-1                             --
│    └─Sequential: 2-1                   --
│    │    └─Linear: 3-1                  64
│    │    └─ELU: 3-2                     --
│    │    └─Linear: 3-3                  1,300
│    │    └─ELU: 3-4                     --
│    └─StateHistoryEncoder: 2-2          --
│    │    └─ELU: 3-5                     --
│    │    └─Sequential: 3-6              1,470
│    │    └─Sequential: 3-7              2,830
│    │    └─Sequential: 3-8              620
│    └─Sequential: 2-3                   --
│    │    └─Linear: 3-9                  8,832
│    │    └─ELU: 3-10                    --
│    └─Sequential: 2-4                   --
│    │    └─Linear: 3-11                 16,512
│    │    └─ELU: 3-12                    --
│    │    └─Linear: 3-13                 16,512
│    │    └─ELU: 3-14                    --
│    │    └─Linear: 3-15                 1,548
│    │    └─Tanh: 3-16                   --
├─Critic: 1-2                            --
│    └─Sequential: 2-5                   --
│    │    └─Linear: 3-17                 6,272
│    │    └─ELU: 3-18                    --
│    └─Sequential: 2-6                   --
│    │    └─Linear: 3-19                 16,512
│    │    └─ELU: 3-20                    --
│    │    └─Linear: 3-21                 16,512
│    │    └─ELU: 3-22                    --
│    │    └─Linear: 3-23                 129
=================================================================
Total params: 89,125
Trainable params: 89,125
Non-trainable params: 0
=================================================================
[2025-02-24 19:01:48] Running RL reset
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
obs_dim 2
/home/isaac/isaacsim/exts/omni.isaac.ml_archive/pip_prebundle/torch/nn/init.py:452: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
